{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05d2d209",
   "metadata": {},
   "source": [
    "# Trends.Earth API - System Monitoring & Rate Limiting\n",
    "\n",
    "This notebook focuses on testing system monitoring, rate limiting, and administrative features of the Trends.Earth API.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup and Configuration](#setup)\n",
    "2. [System Status Monitoring](#system-status)\n",
    "3. [Docker Swarm Monitoring](#swarm-monitoring)\n",
    "4. [Rate Limiting Tests](#rate-limiting)\n",
    "5. [Performance Testing](#performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d4a51c",
   "metadata": {},
   "source": [
    "## Setup and Configuration {#setup}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc9deda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the shared utilities\n",
    "import time\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from trends_earth_api_utils import (\n",
    "    TEST_USERS,\n",
    "    TrendsEarthAPIClient,\n",
    "    display_system_overview,\n",
    "    get_rate_limit_status,\n",
    "    get_swarm_status,\n",
    "    get_system_status,\n",
    "    test_rate_limiting,\n",
    ")\n",
    "\n",
    "# Configuration\n",
    "API_URL = \"http://localhost:5000\"  # Update this for your environment\n",
    "\n",
    "print(f\"🌍 Trends.Earth API URL: {API_URL}\")\n",
    "\n",
    "# Initialize and login as admin (required for most monitoring functions)\n",
    "client = TrendsEarthAPIClient(API_URL)\n",
    "admin_user = TEST_USERS[\"admin\"]\n",
    "login_result = client.login(admin_user[\"email\"], admin_user[\"password\"])\n",
    "\n",
    "if login_result:\n",
    "    print(f\"✅ Logged in as admin: {admin_user['email']}\")\n",
    "else:\n",
    "    print(\"❌ Admin login failed - some tests will be skipped\")\n",
    "    print(\"   System monitoring typically requires admin privileges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a56300a",
   "metadata": {},
   "source": [
    "## System Status Monitoring {#system-status}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deca500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get comprehensive system overview\n",
    "print(\"🖥️  Getting system overview...\")\n",
    "display_system_overview(client)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d85224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze status trends\n",
    "status_logs = get_system_status(client, per_page=10, sort=\"-timestamp\")\n",
    "\n",
    "if status_logs and len(status_logs) >= 2:\n",
    "    latest = status_logs[0]\n",
    "    previous = status_logs[1]\n",
    "\n",
    "    # Calculate changes\n",
    "    active_change = (\n",
    "        latest.get('executions_active', 0) - previous.get('executions_active', 0)\n",
    "    )\n",
    "    running_change = (\n",
    "        latest.get('executions_running', 0) - previous.get('executions_running', 0)\n",
    "    )\n",
    "    users_change = latest.get('users_count', 0) - previous.get('users_count', 0)\n",
    "\n",
    "    print(\"\\n📈 Trends (compared to previous log):\")\n",
    "    active_sign = '+' if active_change >= 0 else ''\n",
    "    print(\n",
    "        f\"   Active Executions: {latest.get('executions_active', 0)} \"\n",
    "        f\"({active_sign}{active_change})\"\n",
    "    )\n",
    "    running_sign = '+' if running_change >= 0 else ''\n",
    "    print(\n",
    "        f\"   Running Executions: {latest.get('executions_running', 0)} \"\n",
    "        f\"({running_sign}{running_change})\"\n",
    "    )\n",
    "    users_sign = '+' if users_change >= 0 else ''\n",
    "    print(\n",
    "        f\"   Total Users: {latest.get('users_count', 0)} \"\n",
    "        f\"({users_sign}{users_change})\"\n",
    "    )\n",
    "else:\n",
    "    print(\"\\n📈 Not enough data for trend analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45e447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize system metrics over time (if matplotlib is available and we have data)\n",
    "if status_logs and len(status_logs) > 5:\n",
    "    print(\"📊 Creating system metrics visualization...\")\n",
    "\n",
    "    try:\n",
    "        # Prepare data for visualization\n",
    "        timestamps = []\n",
    "        active_executions = []\n",
    "        running_executions = []\n",
    "        ready_executions = []\n",
    "\n",
    "        for log in reversed(status_logs[:10]):  # Last 10, oldest first\n",
    "            if log.get(\"timestamp\"):\n",
    "                timestamps.append(log[\"timestamp\"][:16])  # YYYY-MM-DD HH:MM\n",
    "                active_executions.append(log.get(\"executions_active\", 0))\n",
    "                running_executions.append(log.get(\"executions_running\", 0))\n",
    "                ready_executions.append(log.get(\"executions_ready\", 0))\n",
    "\n",
    "        if timestamps:\n",
    "            # Create the plot\n",
    "            fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "            ax.plot(\n",
    "                range(len(timestamps)),\n",
    "                active_executions,\n",
    "                \"b-o\",\n",
    "                label=\"Active Executions\",\n",
    "                markersize=4,\n",
    "            )\n",
    "            ax.plot(\n",
    "                range(len(timestamps)),\n",
    "                running_executions,\n",
    "                \"g-s\",\n",
    "                label=\"Running Executions\",\n",
    "                markersize=4,\n",
    "            )\n",
    "            ax.plot(\n",
    "                range(len(timestamps)),\n",
    "                ready_executions,\n",
    "                \"r-^\",\n",
    "                label=\"Ready Executions\",\n",
    "                markersize=4,\n",
    "            )\n",
    "\n",
    "            ax.set_xlabel(\"Time\")\n",
    "            ax.set_ylabel(\"Number of Executions\")\n",
    "            ax.set_title(\"System Execution Metrics Over Time\")\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "\n",
    "            # Set x-axis labels (show every other timestamp to avoid crowding)\n",
    "            step = max(1, len(timestamps) // 5)\n",
    "            ax.set_xticks(range(0, len(timestamps), step))\n",
    "            ax.set_xticklabels(\n",
    "                [timestamps[i] for i in range(0, len(timestamps), step)], rotation=45\n",
    "            )\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            print(\"✅ System metrics visualization created\")\n",
    "        else:\n",
    "            print(\"⚠️  No valid timestamps for visualization\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️  Could not create visualization: {e}\")\n",
    "else:\n",
    "    print(\"⚠️  Insufficient data for visualization (need at least 5 status logs)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f01b422",
   "metadata": {},
   "source": [
    "## Docker Swarm Monitoring {#swarm-monitoring}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631d945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Docker Swarm status\n",
    "print(\"🐳 Getting Docker Swarm status...\")\n",
    "\n",
    "swarm_info = get_swarm_status(client)\n",
    "\n",
    "if swarm_info:\n",
    "    print(\"✅ Docker Swarm information retrieved:\")\n",
    "\n",
    "    # Display swarm overview\n",
    "    swarm_df = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"Metric\": k.replace(\"_\", \" \").title(),\n",
    "                \"Value\": str(v) if v is not None else \"N/A\",\n",
    "            }\n",
    "            for k, v in swarm_info.items()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    display(HTML(swarm_df.to_html(index=False)))\n",
    "\n",
    "    # Analyze swarm health\n",
    "    print(\"\\n🏥 Swarm Health Analysis:\")\n",
    "\n",
    "    is_active = swarm_info.get(\"swarm_active\", False)\n",
    "    total_nodes = swarm_info.get(\"total_nodes\", 0)\n",
    "    managers = swarm_info.get(\"total_managers\", 0)\n",
    "    workers = swarm_info.get(\"total_workers\", 0)\n",
    "\n",
    "    if is_active:\n",
    "        print(\"   ✅ Swarm is active\")\n",
    "\n",
    "        if managers >= 1:\n",
    "            print(f\"   ✅ Sufficient managers ({managers})\")\n",
    "        else:\n",
    "            print(f\"   ⚠️  Low manager count ({managers})\")\n",
    "\n",
    "        if total_nodes > 0:\n",
    "            print(f\"   ✅ Nodes available ({total_nodes} total, {workers} workers)\")\n",
    "        else:\n",
    "            print(\"   ⚠️  No nodes detected\")\n",
    "\n",
    "        # Check for any additional swarm metrics\n",
    "        if \"services\" in swarm_info:\n",
    "            services = swarm_info[\"services\"]\n",
    "            if isinstance(services, list):\n",
    "                print(f\"   📋 Services running: {len(services)}\")\n",
    "            elif isinstance(services, int):\n",
    "                print(f\"   📋 Services running: {services}\")\n",
    "\n",
    "        if \"tasks\" in swarm_info:\n",
    "            tasks = swarm_info[\"tasks\"]\n",
    "            if isinstance(tasks, (list, dict)):\n",
    "                task_count = (\n",
    "                    len(tasks) if isinstance(tasks, list) else tasks.get(\"total\", 0)\n",
    "                )\n",
    "                print(f\"   🎯 Active tasks: {task_count}\")\n",
    "    else:\n",
    "        print(\"   ❌ Swarm is not active\")\n",
    "else:\n",
    "    print(\"❌ Could not retrieve Docker Swarm status\")\n",
    "    print(\"   This may be normal if not running in swarm mode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8abbe3",
   "metadata": {},
   "source": [
    "## Rate Limiting Tests {#rate-limiting}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff69e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current rate limiting status\n",
    "print(\"🚦 Getting rate limiting status...\")\n",
    "\n",
    "rate_status = get_rate_limit_status(client)\n",
    "\n",
    "if rate_status:\n",
    "    print(\"✅ Rate limiting status retrieved:\")\n",
    "\n",
    "    # Display rate limit information\n",
    "    if isinstance(rate_status, dict):\n",
    "        rate_df = pd.DataFrame(\n",
    "            [\n",
    "                {\n",
    "                    \"Metric\": k.replace(\"_\", \" \").title(),\n",
    "                    \"Value\": str(v) if v is not None else \"N/A\",\n",
    "                }\n",
    "                for k, v in rate_status.items()\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        display(HTML(rate_df.to_html(index=False)))\n",
    "    else:\n",
    "        print(f\"   Status: {rate_status}\")\n",
    "else:\n",
    "    print(\"❌ Could not retrieve rate limiting status\")\n",
    "    print(\"   This feature may require superadmin privileges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992379c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test rate limiting with different request patterns\n",
    "print(\"🧪 Testing rate limiting patterns...\")\n",
    "\n",
    "# Test 1: Burst requests\n",
    "print(\"\\n1️⃣  Burst Request Test (10 requests, no delay):\")\n",
    "burst_results = test_rate_limiting(\n",
    "    client, endpoint=\"/user/me\", requests_count=10, delay=0\n",
    ")\n",
    "\n",
    "# Analyze burst results\n",
    "burst_rate_limited = sum(1 for r in burst_results if r.get(\"rate_limited\", False))\n",
    "burst_avg_time = sum(r.get(\"response_time\", 0) for r in burst_results) / len(\n",
    "    burst_results\n",
    ")\n",
    "\n",
    "print(f\"   Rate limited requests: {burst_rate_limited}/{len(burst_results)}\")\n",
    "print(f\"   Average response time: {burst_avg_time:.2f}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422c5f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Sustained requests\n",
    "print(\"\\n2️⃣  Sustained Request Test (15 requests, 0.5s delay):\")\n",
    "sustained_results = test_rate_limiting(\n",
    "    client, endpoint=\"/user/me\", requests_count=15, delay=0.5\n",
    ")\n",
    "\n",
    "# Analyze sustained results\n",
    "sustained_rate_limited = sum(\n",
    "    1 for r in sustained_results if r.get(\"rate_limited\", False)\n",
    ")\n",
    "sustained_avg_time = sum(r.get(\"response_time\", 0) for r in sustained_results) / len(\n",
    "    sustained_results\n",
    ")\n",
    "\n",
    "print(f\"   Rate limited requests: {sustained_rate_limited}/{len(sustained_results)}\")\n",
    "print(f\"   Average response time: {sustained_avg_time:.2f}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05353295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all test results for analysis\n",
    "results = []\n",
    "if 'burst_results' in locals():\n",
    "    results.extend(burst_results)\n",
    "if 'sustained_results' in locals():\n",
    "    results.extend(sustained_results)\n",
    "\n",
    "if results:\n",
    "    # Calculate statistics\n",
    "    successful = sum(1 for r in results if r['success'])\n",
    "    rate_limited = sum(1 for r in results if r.get('rate_limited', False))\n",
    "    avg_time = (\n",
    "        sum(r['response_time'] for r in results if r['success']) /\n",
    "        max(successful, 1)\n",
    "    )\n",
    "\n",
    "    print(f\"📊 Rate Limiting Test Results ({len(results)} requests):\")\n",
    "    print(f\"     Successful: {successful}/{len(results)}\")\n",
    "    rate_limited_pct = (\n",
    "        (rate_limited / len(results) * 100) if len(results) > 0 else 0\n",
    "    )\n",
    "    print(\n",
    "        f\"     Rate limited: {rate_limited}/{len(results)} \"\n",
    "        f\"({rate_limited_pct:.1f}%)\"\n",
    "    )\n",
    "    print(f\"     Avg response: {avg_time:.2f}ms\")\n",
    "\n",
    "    if rate_limited > 0:\n",
    "        print(\"⚠️  Rate limiting is active!\")\n",
    "    else:\n",
    "        print(\"✅ No rate limiting detected\")\n",
    "else:\n",
    "    print(\"❌ No results from rate limiting test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eb6393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sustained load test (100 requests over 30 seconds)\n",
    "print(\"\\n🔄 Running sustained load test...\")\n",
    "sustained_results = test_rate_limiting(client, num_requests=100, delay=0.3)\n",
    "\n",
    "if sustained_results:\n",
    "    sustained_rate_limited = sum(\n",
    "        1 for r in sustained_results if r.get('rate_limited', False)\n",
    "    )\n",
    "    successful_sustained = sum(1 for r in sustained_results if r['success'])\n",
    "    sustained_avg_time = (\n",
    "        sum(r['response_time'] for r in sustained_results if r['success']) /\n",
    "        max(successful_sustained, 1)\n",
    "    )\n",
    "\n",
    "    sustained_rate_limited_pct = (\n",
    "        (sustained_rate_limited / len(sustained_results) * 100)\n",
    "        if len(sustained_results) > 0 else 0\n",
    "    )\n",
    "\n",
    "    print(\"📊 Sustained Load Test Summary:\")\n",
    "    sustained_summary = {\n",
    "        \"Test Type\": \"Sustained Load\",\n",
    "        \"Duration\": \"30 seconds\",\n",
    "        \"Requests\": len(sustained_results),\n",
    "        \"Rate Limited\": sustained_rate_limited,\n",
    "        \"Rate Limited %\": f\"{sustained_rate_limited_pct:.1f}%\",\n",
    "        \"Avg Response (ms)\": f\"{sustained_avg_time:.2f}\",\n",
    "    }\n",
    "\n",
    "    for key, value in sustained_summary.items():\n",
    "        print(f\"   {key}: {value}\")\n",
    "\n",
    "    # Compare with status endpoint rate limits\n",
    "    try:\n",
    "        status_data = get_rate_limit_status(client)\n",
    "        if status_data and 'rate_limit' in status_data:\n",
    "            rate_limit_info = status_data['rate_limit']\n",
    "            print(\"\\n📋 Rate Limit Configuration:\")\n",
    "            for endpoint, data in rate_limit_info.items():\n",
    "                if data['total'] > 0:\n",
    "                    rate_limited_pct = (\n",
    "                        data['rate_limited'] / data['total'] * 100\n",
    "                    )\n",
    "                    print(f\"   {endpoint}:\")\n",
    "                    print(f\"     Total Requests: {data['total']}\")\n",
    "                    print(f\"     Rate Limited: {data['rate_limited']}\")\n",
    "                    print(f\"     Rate Limited %: {rate_limited_pct:.1f}%\")\n",
    "                    avg_response = data['avg_response_time']\n",
    "                    print(f\"     Avg Response (ms): {avg_response:.2f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️  Could not retrieve rate limit status: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Sustained load test failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf17de2",
   "metadata": {},
   "source": [
    "## Performance Testing {#performance}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad1af06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "import requests\n",
    "\n",
    "# Configuration for concurrent testing\n",
    "BASE_URL = API_URL\n",
    "headers = (\n",
    "    {\"Authorization\": f\"Bearer {client.token}\"}\n",
    "    if hasattr(client, 'token')\n",
    "    else {}\n",
    ")\n",
    "\n",
    "# Concurrent user simulation test\n",
    "print(\"🔄 Starting concurrent test with 3 clients (5 requests each)...\")\n",
    "\n",
    "concurrent_results = []\n",
    "\n",
    "def client_test(client_id, num_requests=5):\n",
    "    \"\"\"Simulate a client making multiple requests\"\"\"\n",
    "    results = []\n",
    "    for i in range(num_requests):\n",
    "        try:\n",
    "            response = requests.get(\n",
    "                f\"{BASE_URL}/api/v1/executions\",\n",
    "                headers=headers,\n",
    "                timeout=30\n",
    "            )\n",
    "            results.append({\n",
    "                'client_id': client_id,\n",
    "                'request_num': i + 1,\n",
    "                'success': response.status_code == 200,\n",
    "                'status_code': response.status_code,\n",
    "                'response_time': response.elapsed.total_seconds() * 1000,\n",
    "                'rate_limited': response.status_code == 429\n",
    "            })\n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                'client_id': client_id,\n",
    "                'request_num': i + 1,\n",
    "                'success': False,\n",
    "                'error': str(e),\n",
    "                'response_time': 0,\n",
    "                'rate_limited': False\n",
    "            })\n",
    "        time.sleep(0.1)  # Small delay between requests\n",
    "    return results\n",
    "\n",
    "# Run concurrent clients\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    futures = [executor.submit(client_test, i+1) for i in range(3)]\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        concurrent_results.extend(future.result())\n",
    "\n",
    "# Analyze concurrent results\n",
    "if concurrent_results:\n",
    "    print(\"\\n📊 Concurrent Test Results:\")\n",
    "\n",
    "    # Group by client\n",
    "    for client_id in range(1, 4):\n",
    "        client_results = [\n",
    "            r for r in concurrent_results\n",
    "            if r.get('client_id') == client_id\n",
    "        ]\n",
    "        successful = sum(1 for r in client_results if r['success'])\n",
    "        avg_time = (\n",
    "            sum(r['response_time'] for r in client_results if r['success']) /\n",
    "            max(successful, 1)\n",
    "        )\n",
    "        print(\n",
    "            f\"   Client {client_id}: {successful}/{len(client_results)} \"\n",
    "            f\"successful, avg {avg_time:.2f}ms\"\n",
    "        )\n",
    "\n",
    "    # Overall statistics\n",
    "    total_requests = len(concurrent_results)\n",
    "    total_successful = sum(1 for r in concurrent_results if r['success'])\n",
    "    avg_response_time = (\n",
    "        sum(r['response_time'] for r in concurrent_results if r['success']) /\n",
    "        max(total_successful, 1)\n",
    "    )\n",
    "\n",
    "    print(\"\\n🎯 Overall Concurrent Results:\")\n",
    "    print(f\"   Total Requests: {total_requests}\")\n",
    "    success_pct = (\n",
    "        (total_successful / total_requests * 100) if total_requests > 0 else 0\n",
    "    )\n",
    "    print(\n",
    "        f\"   Successful: {total_successful} \"\n",
    "        f\"({success_pct:.1f}%)\"\n",
    "    )\n",
    "    print(f\"   Average Response Time: {avg_response_time:.2f}ms\")\n",
    "\n",
    "    if success_pct >= 90:\n",
    "        print(\"✅ Excellent concurrent performance!\")\n",
    "    elif success_pct >= 70:\n",
    "        print(\"⚠️  Good concurrent performance, minor issues detected\")\n",
    "    else:\n",
    "        print(\"🚨 Concurrent performance issues detected!\")\n",
    "else:\n",
    "    print(\"❌ No concurrent test results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11033220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test system under different load patterns\n",
    "print(\"\\n⚡ Testing system responsiveness under load...\")\n",
    "\n",
    "# Baseline test - single request\n",
    "print(\"\\n📊 Baseline Performance:\")\n",
    "baseline_start = time.time()\n",
    "try:\n",
    "    response = client.make_request(\"GET\", \"/user/me\")\n",
    "    baseline_time = (time.time() - baseline_start) * 1000\n",
    "    print(f\"   Single request: {baseline_time:.2f}ms (status: {response.status_code})\")\n",
    "except Exception as e:\n",
    "    print(f\"   Baseline test failed: {e}\")\n",
    "    baseline_time = 0\n",
    "\n",
    "# Load test - rapid sequential requests\n",
    "print(\"\\n🔄 Load Test (20 sequential requests):\")\n",
    "load_times = []\n",
    "load_start = time.time()\n",
    "\n",
    "for i in range(20):\n",
    "    try:\n",
    "        req_start = time.time()\n",
    "        response = client.make_request(\"GET\", \"/user/me\")\n",
    "        req_time = (time.time() - req_start) * 1000\n",
    "        load_times.append(req_time)\n",
    "\n",
    "        if response.status_code == 429:\n",
    "            print(f\"   Request {i + 1}: Rate limited after {req_time:.2f}ms\")\n",
    "        elif i % 5 == 0:  # Print every 5th request\n",
    "            print(f\"   Request {i + 1}: {req_time:.2f}ms\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   Request {i + 1}: Error - {e}\")\n",
    "\n",
    "    time.sleep(0.05)  # 50ms delay\n",
    "\n",
    "total_load_time = (time.time() - load_start) * 1000\n",
    "\n",
    "if load_times:\n",
    "    avg_load_time = sum(load_times) / len(load_times)\n",
    "    print(\"\\n📊 Load Test Results:\")\n",
    "    print(f\"   Requests completed: {len(load_times)}/20\")\n",
    "    print(f\"   Total time: {total_load_time:.2f}ms\")\n",
    "    print(f\"   Average per request: {avg_load_time:.2f}ms\")\n",
    "    print(\n",
    "        f\"   Performance vs baseline: {(avg_load_time / baseline_time):.2f}x\"\n",
    "        if baseline_time > 0\n",
    "        else \"N/A\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   Throughput: {len(load_times) / (total_load_time / 1000):.2f} requests/sec\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f758dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final system status check\n",
    "print(\"\\n🔍 Final system status check after testing...\")\n",
    "\n",
    "# Get fresh system status\n",
    "final_status = get_system_status(client, per_page=1, sort=\"-timestamp\")\n",
    "if final_status:\n",
    "    latest_status = final_status[0]\n",
    "    print(\"📊 Current System State:\")\n",
    "    print(f\"   Active Executions: {latest_status.get('executions_active', 0)}\")\n",
    "    print(f\"   Running Executions: {latest_status.get('executions_running', 0)}\")\n",
    "    print(f\"   Ready Executions: {latest_status.get('executions_ready', 0)}\")\n",
    "    print(f\"   Timestamp: {latest_status.get('timestamp', 'N/A')}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n📊 SYSTEM MONITORING & RATE LIMITING TEST SUMMARY\")\n",
    "print(\"=\" * 65)\n",
    "print(\"✅ System status monitoring tested\")\n",
    "print(\"✅ Docker Swarm monitoring tested\")\n",
    "print(\"✅ Rate limiting functionality tested\")\n",
    "print(\"✅ Performance under various loads tested\")\n",
    "print(\"✅ Concurrent request handling tested\")\n",
    "\n",
    "# Logout\n",
    "client.logout()\n",
    "print(\"\\n🎉 System Monitoring and Rate Limiting tests completed!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
