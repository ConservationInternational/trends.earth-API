{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05d2d209",
   "metadata": {},
   "source": [
    "# Trends.Earth API - System Monitoring & Rate Limiting\n",
    "\n",
    "This notebook focuses on testing system monitoring, rate limiting, and administrative features of the Trends.Earth API.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup and Configuration](#setup)\n",
    "2. [System Status Monitoring](#system-status)\n",
    "3. [Docker Swarm Monitoring](#swarm-monitoring)\n",
    "4. [Rate Limiting Tests](#rate-limiting)\n",
    "5. [Performance Testing](#performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d4a51c",
   "metadata": {},
   "source": [
    "## Setup and Configuration {#setup}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc9deda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the shared utilities\n",
    "import time\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from trends_earth_api_utils import (\n",
    "    TEST_USERS,\n",
    "    TrendsEarthAPIClient,\n",
    "    display_system_overview,\n",
    "    get_rate_limit_status,\n",
    "    get_swarm_status,\n",
    "    get_system_status,\n",
    "    test_rate_limiting,\n",
    ")\n",
    "\n",
    "# Configuration\n",
    "API_URL = \"http://localhost:5000\"  # Update this for your environment\n",
    "\n",
    "print(f\"ğŸŒ Trends.Earth API URL: {API_URL}\")\n",
    "\n",
    "# Initialize and login as admin (required for most monitoring functions)\n",
    "client = TrendsEarthAPIClient(API_URL)\n",
    "admin_user = TEST_USERS[\"admin\"]\n",
    "login_result = client.login(admin_user[\"email\"], admin_user[\"password\"])\n",
    "\n",
    "if login_result:\n",
    "    print(f\"âœ… Logged in as admin: {admin_user['email']}\")\n",
    "else:\n",
    "    print(\"âŒ Admin login failed - some tests will be skipped\")\n",
    "    print(\"   System monitoring typically requires admin privileges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a56300a",
   "metadata": {},
   "source": [
    "## System Status Monitoring {#system-status}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deca500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get comprehensive system overview\n",
    "print(\"ğŸ–¥ï¸  Getting system overview...\")\n",
    "display_system_overview(client)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d85224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get detailed system status logs\n",
    "print(\"ğŸ“Š Getting system status history...\")\n",
    "\n",
    "status_logs = get_system_status(client, per_page=20, sort=\"-timestamp\")\n",
    "\n",
    "if status_logs:\n",
    "    print(f\"âœ… Retrieved {len(status_logs)} status log entries\")\n",
    "\n",
    "    # Create status history table\n",
    "    status_df = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"Timestamp\": log.get(\"timestamp\", \"\")[:19]\n",
    "                if log.get(\"timestamp\")\n",
    "                else \"N/A\",\n",
    "                \"Active Executions\": log.get(\"executions_active\", 0),\n",
    "                \"Running Executions\": log.get(\"executions_running\", 0),\n",
    "                \"Ready Executions\": log.get(\"executions_ready\", 0),\n",
    "                \"Total Users\": log.get(\"users_count\", 0),\n",
    "                \"Total Scripts\": log.get(\"scripts_count\", 0),\n",
    "            }\n",
    "            for log in status_logs[:10]\n",
    "        ]\n",
    "    )  # Show last 10 entries\n",
    "\n",
    "    display(HTML(status_df.to_html(index=False)))\n",
    "\n",
    "    # Analyze trends\n",
    "    if len(status_logs) > 1:\n",
    "        latest = status_logs[0]\n",
    "        previous = status_logs[1]\n",
    "\n",
    "        print(\"\\nğŸ“ˆ Recent Trends:\")\n",
    "\n",
    "        active_change = latest.get(\"executions_active\", 0) - previous.get(\n",
    "            \"executions_active\", 0\n",
    "        )\n",
    "        running_change = latest.get(\"executions_running\", 0) - previous.get(\n",
    "            \"executions_running\", 0\n",
    "        )\n",
    "        users_change = latest.get(\"users_count\", 0) - previous.get(\"users_count\", 0)\n",
    "\n",
    "        print(\n",
    "            f\"   Active Executions: {latest.get('executions_active', 0)} ({'+' if active_change >= 0 else ''}{active_change})\"\n",
    "        )\n",
    "        print(\n",
    "            f\"   Running Executions: {latest.get('executions_running', 0)} ({'+' if running_change >= 0 else ''}{running_change})\"\n",
    "        )\n",
    "        print(\n",
    "            f\"   Total Users: {latest.get('users_count', 0)} ({'+' if users_change >= 0 else ''}{users_change})\"\n",
    "        )\n",
    "else:\n",
    "    print(\"âŒ Could not retrieve system status logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45e447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize system metrics over time (if matplotlib is available and we have data)\n",
    "if status_logs and len(status_logs) > 5:\n",
    "    print(\"ğŸ“Š Creating system metrics visualization...\")\n",
    "\n",
    "    try:\n",
    "        # Prepare data for visualization\n",
    "        timestamps = []\n",
    "        active_executions = []\n",
    "        running_executions = []\n",
    "        ready_executions = []\n",
    "\n",
    "        for log in reversed(status_logs[:10]):  # Last 10, oldest first\n",
    "            if log.get(\"timestamp\"):\n",
    "                timestamps.append(log[\"timestamp\"][:16])  # YYYY-MM-DD HH:MM\n",
    "                active_executions.append(log.get(\"executions_active\", 0))\n",
    "                running_executions.append(log.get(\"executions_running\", 0))\n",
    "                ready_executions.append(log.get(\"executions_ready\", 0))\n",
    "\n",
    "        if timestamps:\n",
    "            # Create the plot\n",
    "            fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "            ax.plot(\n",
    "                range(len(timestamps)),\n",
    "                active_executions,\n",
    "                \"b-o\",\n",
    "                label=\"Active Executions\",\n",
    "                markersize=4,\n",
    "            )\n",
    "            ax.plot(\n",
    "                range(len(timestamps)),\n",
    "                running_executions,\n",
    "                \"g-s\",\n",
    "                label=\"Running Executions\",\n",
    "                markersize=4,\n",
    "            )\n",
    "            ax.plot(\n",
    "                range(len(timestamps)),\n",
    "                ready_executions,\n",
    "                \"r-^\",\n",
    "                label=\"Ready Executions\",\n",
    "                markersize=4,\n",
    "            )\n",
    "\n",
    "            ax.set_xlabel(\"Time\")\n",
    "            ax.set_ylabel(\"Number of Executions\")\n",
    "            ax.set_title(\"System Execution Metrics Over Time\")\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "\n",
    "            # Set x-axis labels (show every other timestamp to avoid crowding)\n",
    "            step = max(1, len(timestamps) // 5)\n",
    "            ax.set_xticks(range(0, len(timestamps), step))\n",
    "            ax.set_xticklabels(\n",
    "                [timestamps[i] for i in range(0, len(timestamps), step)], rotation=45\n",
    "            )\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            print(\"âœ… System metrics visualization created\")\n",
    "        else:\n",
    "            print(\"âš ï¸  No valid timestamps for visualization\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Could not create visualization: {e}\")\n",
    "else:\n",
    "    print(\"âš ï¸  Insufficient data for visualization (need at least 5 status logs)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f01b422",
   "metadata": {},
   "source": [
    "## Docker Swarm Monitoring {#swarm-monitoring}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631d945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Docker Swarm status\n",
    "print(\"ğŸ³ Getting Docker Swarm status...\")\n",
    "\n",
    "swarm_info = get_swarm_status(client)\n",
    "\n",
    "if swarm_info:\n",
    "    print(\"âœ… Docker Swarm information retrieved:\")\n",
    "\n",
    "    # Display swarm overview\n",
    "    swarm_df = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"Metric\": k.replace(\"_\", \" \").title(),\n",
    "                \"Value\": str(v) if v is not None else \"N/A\",\n",
    "            }\n",
    "            for k, v in swarm_info.items()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    display(HTML(swarm_df.to_html(index=False)))\n",
    "\n",
    "    # Analyze swarm health\n",
    "    print(\"\\nğŸ¥ Swarm Health Analysis:\")\n",
    "\n",
    "    is_active = swarm_info.get(\"swarm_active\", False)\n",
    "    total_nodes = swarm_info.get(\"total_nodes\", 0)\n",
    "    managers = swarm_info.get(\"total_managers\", 0)\n",
    "    workers = swarm_info.get(\"total_workers\", 0)\n",
    "\n",
    "    if is_active:\n",
    "        print(\"   âœ… Swarm is active\")\n",
    "\n",
    "        if managers >= 1:\n",
    "            print(f\"   âœ… Sufficient managers ({managers})\")\n",
    "        else:\n",
    "            print(f\"   âš ï¸  Low manager count ({managers})\")\n",
    "\n",
    "        if total_nodes > 0:\n",
    "            print(f\"   âœ… Nodes available ({total_nodes} total, {workers} workers)\")\n",
    "        else:\n",
    "            print(\"   âš ï¸  No nodes detected\")\n",
    "\n",
    "        # Check for any additional swarm metrics\n",
    "        if \"services\" in swarm_info:\n",
    "            services = swarm_info[\"services\"]\n",
    "            if isinstance(services, list):\n",
    "                print(f\"   ğŸ“‹ Services running: {len(services)}\")\n",
    "            elif isinstance(services, int):\n",
    "                print(f\"   ğŸ“‹ Services running: {services}\")\n",
    "\n",
    "        if \"tasks\" in swarm_info:\n",
    "            tasks = swarm_info[\"tasks\"]\n",
    "            if isinstance(tasks, (list, dict)):\n",
    "                task_count = (\n",
    "                    len(tasks) if isinstance(tasks, list) else tasks.get(\"total\", 0)\n",
    "                )\n",
    "                print(f\"   ğŸ¯ Active tasks: {task_count}\")\n",
    "    else:\n",
    "        print(\"   âŒ Swarm is not active\")\n",
    "else:\n",
    "    print(\"âŒ Could not retrieve Docker Swarm status\")\n",
    "    print(\"   This may be normal if not running in swarm mode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8abbe3",
   "metadata": {},
   "source": [
    "## Rate Limiting Tests {#rate-limiting}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff69e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current rate limiting status\n",
    "print(\"ğŸš¦ Getting rate limiting status...\")\n",
    "\n",
    "rate_status = get_rate_limit_status(client)\n",
    "\n",
    "if rate_status:\n",
    "    print(\"âœ… Rate limiting status retrieved:\")\n",
    "\n",
    "    # Display rate limit information\n",
    "    if isinstance(rate_status, dict):\n",
    "        rate_df = pd.DataFrame(\n",
    "            [\n",
    "                {\n",
    "                    \"Metric\": k.replace(\"_\", \" \").title(),\n",
    "                    \"Value\": str(v) if v is not None else \"N/A\",\n",
    "                }\n",
    "                for k, v in rate_status.items()\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        display(HTML(rate_df.to_html(index=False)))\n",
    "    else:\n",
    "        print(f\"   Status: {rate_status}\")\n",
    "else:\n",
    "    print(\"âŒ Could not retrieve rate limiting status\")\n",
    "    print(\"   This feature may require superadmin privileges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992379c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test rate limiting with different request patterns\n",
    "print(\"ğŸ§ª Testing rate limiting patterns...\")\n",
    "\n",
    "# Test 1: Burst requests\n",
    "print(\"\\n1ï¸âƒ£  Burst Request Test (10 requests, no delay):\")\n",
    "burst_results = test_rate_limiting(\n",
    "    client, endpoint=\"/user/me\", requests_count=10, delay=0\n",
    ")\n",
    "\n",
    "# Analyze burst results\n",
    "burst_rate_limited = sum(1 for r in burst_results if r.get(\"rate_limited\", False))\n",
    "burst_avg_time = sum(r.get(\"response_time\", 0) for r in burst_results) / len(\n",
    "    burst_results\n",
    ")\n",
    "\n",
    "print(f\"   Rate limited requests: {burst_rate_limited}/{len(burst_results)}\")\n",
    "print(f\"   Average response time: {burst_avg_time:.2f}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422c5f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Sustained requests\n",
    "print(\"\\n2ï¸âƒ£  Sustained Request Test (15 requests, 0.5s delay):\")\n",
    "sustained_results = test_rate_limiting(\n",
    "    client, endpoint=\"/user/me\", requests_count=15, delay=0.5\n",
    ")\n",
    "\n",
    "# Analyze sustained results\n",
    "sustained_rate_limited = sum(\n",
    "    1 for r in sustained_results if r.get(\"rate_limited\", False)\n",
    ")\n",
    "sustained_avg_time = sum(r.get(\"response_time\", 0) for r in sustained_results) / len(\n",
    "    sustained_results\n",
    ")\n",
    "\n",
    "print(f\"   Rate limited requests: {sustained_rate_limited}/{len(sustained_results)}\")\n",
    "print(f\"   Average response time: {sustained_avg_time:.2f}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05353295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Different endpoints\n",
    "print(\"\\n3ï¸âƒ£  Multi-endpoint Test:\")\n",
    "\n",
    "test_endpoints = [\n",
    "    (\"/user/me\", \"User Profile\"),\n",
    "    (\"/script\", \"Script List\"),\n",
    "    (\"/execution/user\", \"User Executions\"),\n",
    "]\n",
    "\n",
    "endpoint_results = {}\n",
    "\n",
    "for endpoint, name in test_endpoints:\n",
    "    print(f\"\\n   Testing {name} ({endpoint}):\")\n",
    "    results = test_rate_limiting(client, endpoint=endpoint, requests_count=8, delay=0.2)\n",
    "\n",
    "    rate_limited = sum(1 for r in results if r.get(\"rate_limited\", False))\n",
    "    avg_time = sum(r.get(\"response_time\", 0) for r in results) / len(results)\n",
    "\n",
    "    endpoint_results[name] = {\n",
    "        \"total\": len(results),\n",
    "        \"rate_limited\": rate_limited,\n",
    "        \"avg_response_time\": avg_time,\n",
    "    }\n",
    "\n",
    "    print(\n",
    "        f\"     Rate limited: {rate_limited}/{len(results)} ({(rate_limited / len(results) * 100):.1f}%)\"\n",
    "    )\n",
    "    print(f\"     Avg response: {avg_time:.2f}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eb6393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rate limiting summary\n",
    "print(\"\\nğŸ“Š Rate Limiting Test Summary:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Summary table\n",
    "summary_data = [\n",
    "    {\n",
    "        \"Test Type\": \"Burst (no delay)\",\n",
    "        \"Requests\": len(burst_results),\n",
    "        \"Rate Limited\": burst_rate_limited,\n",
    "        \"Rate Limited %\": f\"{(burst_rate_limited / len(burst_results) * 100):.1f}%\",\n",
    "        \"Avg Response (ms)\": f\"{burst_avg_time:.2f}\",\n",
    "    },\n",
    "    {\n",
    "        \"Test Type\": \"Sustained (0.5s delay)\",\n",
    "        \"Requests\": len(sustained_results),\n",
    "        \"Rate Limited\": sustained_rate_limited,\n",
    "        \"Rate Limited %\": f\"{(sustained_rate_limited / len(sustained_results) * 100):.1f}%\",\n",
    "        \"Avg Response (ms)\": f\"{sustained_avg_time:.2f}\",\n",
    "    },\n",
    "]\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "display(HTML(summary_df.to_html(index=False)))\n",
    "\n",
    "# Endpoint comparison\n",
    "if endpoint_results:\n",
    "    print(\"\\nğŸ¯ Endpoint Comparison:\")\n",
    "    endpoint_df = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"Endpoint\": name,\n",
    "                \"Total Requests\": data[\"total\"],\n",
    "                \"Rate Limited\": data[\"rate_limited\"],\n",
    "                \"Rate Limited %\": f\"{(data['rate_limited'] / data['total'] * 100):.1f}%\",\n",
    "                \"Avg Response (ms)\": f\"{data['avg_response_time']:.2f}\",\n",
    "            }\n",
    "            for name, data in endpoint_results.items()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    display(HTML(endpoint_df.to_html(index=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf17de2",
   "metadata": {},
   "source": [
    "## Performance Testing {#performance}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad1af06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test concurrent requests with multiple clients\n",
    "print(\"ğŸš€ Testing concurrent request performance...\")\n",
    "\n",
    "\n",
    "def make_concurrent_requests(client_id, num_requests=5):\n",
    "    \"\"\"Make concurrent requests from a single client\"\"\"\n",
    "    test_client = TrendsEarthAPIClient(API_URL)\n",
    "    regular_user = TEST_USERS[\"regular\"]\n",
    "\n",
    "    # Login\n",
    "    login_success = test_client.login(regular_user[\"email\"], regular_user[\"password\"])\n",
    "    if not login_success:\n",
    "        return {\"client_id\": client_id, \"error\": \"Login failed\"}\n",
    "\n",
    "    results = []\n",
    "    for i in range(num_requests):\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            response = test_client.make_request(\"GET\", \"/user/me\")\n",
    "            end_time = time.time()\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"request\": i + 1,\n",
    "                    \"status_code\": response.status_code,\n",
    "                    \"response_time\": (end_time - start_time) * 1000,\n",
    "                    \"success\": response.status_code < 400,\n",
    "                }\n",
    "            )\n",
    "        except Exception as e:\n",
    "            results.append({\"request\": i + 1, \"error\": str(e), \"success\": False})\n",
    "\n",
    "        time.sleep(0.1)  # Small delay between requests\n",
    "\n",
    "    # Logout\n",
    "    test_client.logout()\n",
    "\n",
    "    return {\"client_id\": client_id, \"results\": results}\n",
    "\n",
    "\n",
    "# Run concurrent tests with 3 clients\n",
    "print(\"ğŸ“Š Starting concurrent test with 3 clients (5 requests each)...\")\n",
    "\n",
    "import concurrent.futures\n",
    "\n",
    "concurrent_results = []\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    futures = [executor.submit(make_concurrent_requests, i, 5) for i in range(3)]\n",
    "    concurrent_results = [\n",
    "        future.result() for future in concurrent.futures.as_completed(futures)\n",
    "    ]\n",
    "\n",
    "# Analyze concurrent results\n",
    "print(\"\\nğŸ“ˆ Concurrent Request Analysis:\")\n",
    "\n",
    "total_requests = 0\n",
    "total_successful = 0\n",
    "total_response_time = 0\n",
    "response_times = []\n",
    "\n",
    "for client_result in concurrent_results:\n",
    "    client_id = client_result[\"client_id\"]\n",
    "\n",
    "    if \"error\" in client_result:\n",
    "        print(f\"   Client {client_id}: {client_result['error']}\")\n",
    "        continue\n",
    "\n",
    "    results = client_result[\"results\"]\n",
    "    successful = sum(1 for r in results if r.get(\"success\", False))\n",
    "    avg_time = sum(\n",
    "        r.get(\"response_time\", 0) for r in results if \"response_time\" in r\n",
    "    ) / len(results)\n",
    "\n",
    "    print(\n",
    "        f\"   Client {client_id}: {successful}/{len(results)} successful, avg {avg_time:.2f}ms\"\n",
    "    )\n",
    "\n",
    "    total_requests += len(results)\n",
    "    total_successful += successful\n",
    "\n",
    "    for r in results:\n",
    "        if \"response_time\" in r:\n",
    "            response_times.append(r[\"response_time\"])\n",
    "\n",
    "if response_times:\n",
    "    avg_response_time = sum(response_times) / len(response_times)\n",
    "    min_response_time = min(response_times)\n",
    "    max_response_time = max(response_times)\n",
    "\n",
    "    print(\"\\nğŸ¯ Overall Performance:\")\n",
    "    print(f\"   Total Requests: {total_requests}\")\n",
    "    print(\n",
    "        f\"   Successful: {total_successful} ({(total_successful / total_requests * 100):.1f}%)\"\n",
    "    )\n",
    "    print(f\"   Average Response Time: {avg_response_time:.2f}ms\")\n",
    "    print(f\"   Min Response Time: {min_response_time:.2f}ms\")\n",
    "    print(f\"   Max Response Time: {max_response_time:.2f}ms\")\n",
    "else:\n",
    "    print(\"âŒ No valid response times collected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11033220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test system under different load patterns\n",
    "print(\"\\nâš¡ Testing system responsiveness under load...\")\n",
    "\n",
    "# Baseline test - single request\n",
    "print(\"\\nğŸ“Š Baseline Performance:\")\n",
    "baseline_start = time.time()\n",
    "try:\n",
    "    response = client.make_request(\"GET\", \"/user/me\")\n",
    "    baseline_time = (time.time() - baseline_start) * 1000\n",
    "    print(f\"   Single request: {baseline_time:.2f}ms (status: {response.status_code})\")\n",
    "except Exception as e:\n",
    "    print(f\"   Baseline test failed: {e}\")\n",
    "    baseline_time = 0\n",
    "\n",
    "# Load test - rapid sequential requests\n",
    "print(\"\\nğŸ”„ Load Test (20 sequential requests):\")\n",
    "load_times = []\n",
    "load_start = time.time()\n",
    "\n",
    "for i in range(20):\n",
    "    try:\n",
    "        req_start = time.time()\n",
    "        response = client.make_request(\"GET\", \"/user/me\")\n",
    "        req_time = (time.time() - req_start) * 1000\n",
    "        load_times.append(req_time)\n",
    "\n",
    "        if response.status_code == 429:\n",
    "            print(f\"   Request {i + 1}: Rate limited after {req_time:.2f}ms\")\n",
    "        elif i % 5 == 0:  # Print every 5th request\n",
    "            print(f\"   Request {i + 1}: {req_time:.2f}ms\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   Request {i + 1}: Error - {e}\")\n",
    "\n",
    "    time.sleep(0.05)  # 50ms delay\n",
    "\n",
    "total_load_time = (time.time() - load_start) * 1000\n",
    "\n",
    "if load_times:\n",
    "    avg_load_time = sum(load_times) / len(load_times)\n",
    "    print(\"\\nğŸ“Š Load Test Results:\")\n",
    "    print(f\"   Requests completed: {len(load_times)}/20\")\n",
    "    print(f\"   Total time: {total_load_time:.2f}ms\")\n",
    "    print(f\"   Average per request: {avg_load_time:.2f}ms\")\n",
    "    print(\n",
    "        f\"   Performance vs baseline: {(avg_load_time / baseline_time):.2f}x\"\n",
    "        if baseline_time > 0\n",
    "        else \"N/A\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   Throughput: {len(load_times) / (total_load_time / 1000):.2f} requests/sec\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f758dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final system status check\n",
    "print(\"\\nğŸ” Final system status check after testing...\")\n",
    "\n",
    "# Get fresh system status\n",
    "final_status = get_system_status(client, per_page=1, sort=\"-timestamp\")\n",
    "if final_status:\n",
    "    latest_status = final_status[0]\n",
    "    print(\"ğŸ“Š Current System State:\")\n",
    "    print(f\"   Active Executions: {latest_status.get('executions_active', 0)}\")\n",
    "    print(f\"   Running Executions: {latest_status.get('executions_running', 0)}\")\n",
    "    print(f\"   Ready Executions: {latest_status.get('executions_ready', 0)}\")\n",
    "    print(f\"   Timestamp: {latest_status.get('timestamp', 'N/A')}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\nğŸ“Š SYSTEM MONITORING & RATE LIMITING TEST SUMMARY\")\n",
    "print(\"=\" * 65)\n",
    "print(\"âœ… System status monitoring tested\")\n",
    "print(\"âœ… Docker Swarm monitoring tested\")\n",
    "print(\"âœ… Rate limiting functionality tested\")\n",
    "print(\"âœ… Performance under various loads tested\")\n",
    "print(\"âœ… Concurrent request handling tested\")\n",
    "\n",
    "# Logout\n",
    "client.logout()\n",
    "print(\"\\nğŸ‰ System Monitoring and Rate Limiting tests completed!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
